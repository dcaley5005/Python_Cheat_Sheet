{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "decision_tree_regression.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyPxmZNIwDPeKeMslsCnBzyw"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3cas2_1T98w",
    "colab_type": "text"
   },
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IODliia6U1xO",
    "colab_type": "text"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y98nA5UdU6Hf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import redshift_connector\n",
    "import keyring"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpjZ43YlU8eI",
    "colab_type": "text"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'with tmp_errors as (\n    select distinct order_id\n    from factdata.errors\n    where external_flag = TRUE\n)\n\n\nselect customer_orders.customer_order_id,\n       customer_orders.date_placed,\n       datediff('d', customer_orders.date_placed, customer_orders.date_delivered) days_deliverd,\n       customer_orders.net_price,\n       customer_orders.total_units,\n       count(distinct designs.design_id)                                          designs_prior_30,\n       nvl2(tmp_errors.order_id, 1, 0)                                            errors,\n       round(median_household_income::numeric(20) * population::numeric(20))      zip_wealth,\n       segment_name_uber,\n       case\n           when segment_name_uber in ('Friends & Family', 'All Athletics', 'Organizations')\n               then 'Family, Org, & Athletics'\n           else segment_name_uber end   as                                        segment_name_ultra,\n       case when segment_name_ultra = 'Family, Org, & Athletics' then 1\n            when segment_name_ultra = 'Students & Schools'\n            else 3 end segment_rank_ultra,\n       style_uber_category,\n       case\n           when style_uber_category != 'Casual Apparel' then 'Remaining Apparel'\n           else style_uber_category end as                                        style_category_utlra,\n       case\n           when sales_channel_attributed in ('KAM', 'NAM', 'Outreach') then 'Proactive Channel'\n           else 'Reactive Channel' end  as                                        uber_sales_channel_attr,\n       case\n           when sales_channel_placed in ('KAM', 'NAM', 'Outreach') then 'Proactive Channel'\n           else 'Reactive Channel' end  as                                        uber_sales_channel_placed,\n       sales_bulk_following_365\nfrom general_use.customer_orders\n         join general_use.customer_orders_purchase_window using (customer_order_id)\n         join general_use.customer_orders_segmentation using (customer_order_id)\n         join general_use.customer_orders_products using (customer_order_id)\n         left join factdata.designs\n                   on customer_account_id = account_id\n                       and\n                      convert_timezone('America/New_York', date_design_saved) between timestamp_placed - 30 and timestamp_placed\n         left join tmp_errors\n                   on customer_order_id = order_id\n         left join factdata.orders\n                   on customer_order_id = orders.order_id\n         left join dim_address bill_address\n                   on bill_address_id = address_id\n         left join rawdata.static_zip_to_zcta\n                   on left(bill_address.zipcode, 5) = static_zip_to_zcta.zipcode\n         left join rawdata.static_household_income\n                   on static_zip_to_zcta.zcta = static_household_income.zipcode\n                       and customer_orders.date_placed between date_census_start and date_census_end\nwhere is_fix = 0\n  and is_canceled = 0\n  and business_line = 'Bulk'\n  -- look at a customer's first purchase only\n  and prior_bulk_purchase_date is null\n  -- look only at customers who had a repeat order within a year\n  and days_to_next_bulk_purchase <= 365\n  and sales_bulk_following_365 > 0\n  -- pull data from two years before COVID started\n  and customer_orders.date_placed < dateadd('day', -365, '2020-03-01')\n  and customer_orders.date_placed >= dateadd('day', -365 * 2, '2020-03-01')\n  and segment_name_uber not in ('None', 'Ignore')\n  and style_uber_category not in ('Health & Wellness', 'None')\n  and customer_orders.net_price > 0\n  and customer_orders.date_delivered is not null\n  and median_household_income is not null\ngroup by 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\n': {'S': 'ERROR', 'C': '42601', 'M': 'syntax error at or near \"else\"', 'P': '1062', 'F': '/home/ec2-user/padb/src/pg/src/backend/parser/parser_scan.l', 'L': '714', 'R': 'yyerror'}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\redshift_connector\\core.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, cursor, operation, vals)\u001B[0m\n\u001B[0;32m   1512\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1513\u001B[1;33m             \u001B[0mps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcache\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"ps\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1514\u001B[0m             \u001B[0mcursor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: (\"with tmp_errors as (\\n    select distinct order_id\\n    from factdata.errors\\n    where external_flag = TRUE\\n)\\n\\n\\nselect customer_orders.customer_order_id,\\n       customer_orders.date_placed,\\n       datediff('d', customer_orders.date_placed, customer_orders.date_delivered) days_deliverd,\\n       customer_orders.net_price,\\n       customer_orders.total_units,\\n       count(distinct designs.design_id)                                          designs_prior_30,\\n       nvl2(tmp_errors.order_id, 1, 0)                                            errors,\\n       round(median_household_income::numeric(20) * population::numeric(20))      zip_wealth,\\n       segment_name_uber,\\n       case\\n           when segment_name_uber in ('Friends & Family', 'All Athletics', 'Organizations')\\n               then 'Family, Org, & Athletics'\\n           else segment_name_uber end   as                                        segment_name_ultra,\\n       case when segment_name_ultra = 'Family, Org, & Athletics' then 1\\n            when segment_name_ultra = 'Students & Schools'\\n            else 3 end segment_rank_ultra,\\n       style_uber_category,\\n       case\\n           when style_uber_category != 'Casual Apparel' then 'Remaining Apparel'\\n           else style_uber_category end as                                        style_category_utlra,\\n       case\\n           when sales_channel_attributed in ('KAM', 'NAM', 'Outreach') then 'Proactive Channel'\\n           else 'Reactive Channel' end  as                                        uber_sales_channel_attr,\\n       case\\n           when sales_channel_placed in ('KAM', 'NAM', 'Outreach') then 'Proactive Channel'\\n           else 'Reactive Channel' end  as                                        uber_sales_channel_placed,\\n       sales_bulk_following_365\\nfrom general_use.customer_orders\\n         join general_use.customer_orders_purchase_window using (customer_order_id)\\n         join general_use.customer_orders_segmentation using (customer_order_id)\\n         join general_use.customer_orders_products using (customer_order_id)\\n         left join factdata.designs\\n                   on customer_account_id = account_id\\n                       and\\n                      convert_timezone('America/New_York', date_design_saved) between timestamp_placed - 30 and timestamp_placed\\n         left join tmp_errors\\n                   on customer_order_id = order_id\\n         left join factdata.orders\\n                   on customer_order_id = orders.order_id\\n         left join dim_address bill_address\\n                   on bill_address_id = address_id\\n         left join rawdata.static_zip_to_zcta\\n                   on left(bill_address.zipcode, 5) = static_zip_to_zcta.zipcode\\n         left join rawdata.static_household_income\\n                   on static_zip_to_zcta.zcta = static_household_income.zipcode\\n                       and customer_orders.date_placed between date_census_start and date_census_end\\nwhere is_fix = 0\\n  and is_canceled = 0\\n  and business_line = 'Bulk'\\n  -- look at a customer's first purchase only\\n  and prior_bulk_purchase_date is null\\n  -- look only at customers who had a repeat order within a year\\n  and days_to_next_bulk_purchase <= 365\\n  and sales_bulk_following_365 > 0\\n  -- pull data from two years before COVID started\\n  and customer_orders.date_placed < dateadd('day', -365, '2020-03-01')\\n  and customer_orders.date_placed >= dateadd('day', -365 * 2, '2020-03-01')\\n  and segment_name_uber not in ('None', 'Ignore')\\n  and style_uber_category not in ('Health & Wellness', 'None')\\n  and customer_orders.net_price > 0\\n  and customer_orders.date_delivered is not null\\n  and median_household_income is not null\\ngroup by 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n\", ())",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mProgrammingError\u001B[0m                          Traceback (most recent call last)",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2055\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2056\u001B[1;33m             \u001B[0mcur\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2057\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mcur\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\redshift_connector\\cursor.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, operation, args, stream, merge_socket_read)\u001B[0m\n\u001B[0;32m    230\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_c\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmerge_socket_read\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmerge_socket_read\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_c\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moperation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\redshift_connector\\core.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, cursor, operation, vals)\u001B[0m\n\u001B[0;32m   1582\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1583\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandle_messages\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcursor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1584\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\redshift_connector\\core.py\u001B[0m in \u001B[0;36mhandle_messages\u001B[1;34m(self, cursor)\u001B[0m\n\u001B[0;32m   1850\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1851\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1852\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mProgrammingError\u001B[0m: {'S': 'ERROR', 'C': '42601', 'M': 'syntax error at or near \"else\"', 'P': '1062', 'F': '/home/ec2-user/padb/src/pg/src/backend/parser/parser_scan.l', 'L': '714', 'R': 'yyerror'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mDatabaseError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\DAN~1.CAL\\AppData\\Local\\Temp/ipykernel_250276/924763130.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;31m# Running Query from sql file\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[0mdataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_sql_query\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msql_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;31m# Removing Binary headers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36mread_sql_query\u001B[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001B[0m\n\u001B[0;32m    434\u001B[0m     \"\"\"\n\u001B[0;32m    435\u001B[0m     \u001B[0mpandas_sql\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpandasSQL_builder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcon\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 436\u001B[1;33m     return pandas_sql.read_query(\n\u001B[0m\u001B[0;32m    437\u001B[0m         \u001B[0msql\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m         \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mindex_col\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36mread_query\u001B[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001B[0m\n\u001B[0;32m   2114\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2115\u001B[0m         \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msql\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2116\u001B[1;33m         \u001B[0mcursor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2117\u001B[0m         \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mcol_desc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mcol_desc\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcursor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdescription\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2066\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2067\u001B[0m             \u001B[0mex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDatabaseError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2068\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mex\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mexc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2069\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2070\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mDatabaseError\u001B[0m: Execution failed on sql 'with tmp_errors as (\n    select distinct order_id\n    from factdata.errors\n    where external_flag = TRUE\n)\n\n\nselect customer_orders.customer_order_id,\n       customer_orders.date_placed,\n       datediff('d', customer_orders.date_placed, customer_orders.date_delivered) days_deliverd,\n       customer_orders.net_price,\n       customer_orders.total_units,\n       count(distinct designs.design_id)                                          designs_prior_30,\n       nvl2(tmp_errors.order_id, 1, 0)                                            errors,\n       round(median_household_income::numeric(20) * population::numeric(20))      zip_wealth,\n       segment_name_uber,\n       case\n           when segment_name_uber in ('Friends & Family', 'All Athletics', 'Organizations')\n               then 'Family, Org, & Athletics'\n           else segment_name_uber end   as                                        segment_name_ultra,\n       case when segment_name_ultra = 'Family, Org, & Athletics' then 1\n            when segment_name_ultra = 'Students & Schools'\n            else 3 end segment_rank_ultra,\n       style_uber_category,\n       case\n           when style_uber_category != 'Casual Apparel' then 'Remaining Apparel'\n           else style_uber_category end as                                        style_category_utlra,\n       case\n           when sales_channel_attributed in ('KAM', 'NAM', 'Outreach') then 'Proactive Channel'\n           else 'Reactive Channel' end  as                                        uber_sales_channel_attr,\n       case\n           when sales_channel_placed in ('KAM', 'NAM', 'Outreach') then 'Proactive Channel'\n           else 'Reactive Channel' end  as                                        uber_sales_channel_placed,\n       sales_bulk_following_365\nfrom general_use.customer_orders\n         join general_use.customer_orders_purchase_window using (customer_order_id)\n         join general_use.customer_orders_segmentation using (customer_order_id)\n         join general_use.customer_orders_products using (customer_order_id)\n         left join factdata.designs\n                   on customer_account_id = account_id\n                       and\n                      convert_timezone('America/New_York', date_design_saved) between timestamp_placed - 30 and timestamp_placed\n         left join tmp_errors\n                   on customer_order_id = order_id\n         left join factdata.orders\n                   on customer_order_id = orders.order_id\n         left join dim_address bill_address\n                   on bill_address_id = address_id\n         left join rawdata.static_zip_to_zcta\n                   on left(bill_address.zipcode, 5) = static_zip_to_zcta.zipcode\n         left join rawdata.static_household_income\n                   on static_zip_to_zcta.zcta = static_household_income.zipcode\n                       and customer_orders.date_placed between date_census_start and date_census_end\nwhere is_fix = 0\n  and is_canceled = 0\n  and business_line = 'Bulk'\n  -- look at a customer's first purchase only\n  and prior_bulk_purchase_date is null\n  -- look only at customers who had a repeat order within a year\n  and days_to_next_bulk_purchase <= 365\n  and sales_bulk_following_365 > 0\n  -- pull data from two years before COVID started\n  and customer_orders.date_placed < dateadd('day', -365, '2020-03-01')\n  and customer_orders.date_placed >= dateadd('day', -365 * 2, '2020-03-01')\n  and segment_name_uber not in ('None', 'Ignore')\n  and style_uber_category not in ('Health & Wellness', 'None')\n  and customer_orders.net_price > 0\n  and customer_orders.date_delivered is not null\n  and median_household_income is not null\ngroup by 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\n': {'S': 'ERROR', 'C': '42601', 'M': 'syntax error at or near \"else\"', 'P': '1062', 'F': '/home/ec2-user/padb/src/pg/src/backend/parser/parser_scan.l', 'L': '714', 'R': 'yyerror'}"
     ]
    }
   ],
   "source": [
    "### Importing via Redshift\n",
    "pwd = keyring.get_password(\"redshift-production.db.customink.com\", \"dan.caley\")\n",
    "\n",
    "# Connecting to redshift\n",
    "# https://docs.aws.amazon.com/redshift/latest/mgmt/python-connect-examples.html#python-connect-query\n",
    "conn = redshift_connector.connect(\n",
    "    host='redshift-production.db.customink.com',\n",
    "    database='cink',\n",
    "    user='dan.caley',\n",
    "    password= pwd\n",
    ")\n",
    "\n",
    "# Reading SQL File\n",
    "open_file = open('sql_code.sql','r')\n",
    "sql_file = open_file.read()\n",
    "open_file.close()\n",
    "\n",
    "# Running Query from sql file\n",
    "dataset = pd.read_sql_query(sql_file, conn)\n",
    "\n",
    "# Removing Binary headers\n",
    "remove_binary = dataset.columns.astype(str).str.replace(\"'b\",'')\n",
    "dataset.columns = remove_binary\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check NA's\n",
    "dataset.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pLVaXoYVU_Uy",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dataset = pd.read_csv('Data.csv')\n",
    "data = dataset[['days_deliverd','net_price','total_units','designs_prior_30','errors','sales_bulk_following_365']]\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPJXMyyUJbWn",
    "colab_type": "text"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rFOzpjaiJd5B",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g16qFkFQVC35",
    "colab_type": "text"
   },
   "source": [
    "## Training the Decision Tree Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SLDKyv1SVUqS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(random_state=0)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nao9cdO6IgNb",
    "colab_type": "text"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EebHA3EOIkQK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 460.64  234.3 ]\n",
      " [ 328.48  277.75]\n",
      " [ 986.28  272.14]\n",
      " ...\n",
      " [ 513.06  828.24]\n",
      " [ 206.56 3610.11]\n",
      " [5921.1  1779.  ]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4nELFnnIod1",
    "colab_type": "text"
   },
   "source": [
    "## Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_G2QS1UoIsTZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.47186291830950844"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}